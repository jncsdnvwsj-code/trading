{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2ea7c4",
   "metadata": {},
   "source": [
    "# Portfolio Optimization: Mean-Variance and Black-Litterman Models\n",
    "\n",
    "## A Comprehensive Guide to Building Optimized Investment Portfolios\n",
    "\n",
    "This notebook walks through the complete process of portfolio optimization, from data loading through strategy comparison and stress testing.\n",
    "\n",
    "**Topics Covered:**\n",
    "1. Historical data loading and analysis\n",
    "2. Mean-Variance optimization (Markowitz theory)\n",
    "3. Black-Litterman model with investor views\n",
    "4. Portfolio backtesting with transaction costs\n",
    "5. Stress testing and scenario analysis\n",
    "6. Rebalancing strategies comparison\n",
    "7. Performance metrics and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d506e826",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from data_utils import (\n",
    "    load_historical_data,\n",
    "    calculate_returns,\n",
    "    calculate_cov_matrix,\n",
    "    calculate_expected_returns,\n",
    "    get_asset_names\n",
    ")\n",
    "from mean_variance import MeanVarianceOptimizer\n",
    "from black_litterman import BlackLittermanModel\n",
    "from backtester import PortfolioBacktester\n",
    "from scenario_analysis import ScenarioAnalyzer\n",
    "from portfolio_utils import PerformanceReport, diversification_ratio\n",
    "\n",
    "print(\"✓ Custom modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f31af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'JPM', 'XOM', 'JNJ']\n",
    "INITIAL_CAPITAL = 1000000\n",
    "RISK_FREE_RATE = 0.02\n",
    "\n",
    "print(f\"Assets to analyze: {', '.join(TICKERS)}\")\n",
    "print(f\"Initial capital: ${INITIAL_CAPITAL:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f4ebfa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Historical Data Loading and Analysis\n",
    "\n",
    "First, let's load historical price data and compute fundamental statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa9e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 5 years of historical data\n",
    "print(\"Loading historical data...\")\n",
    "prices = load_historical_data(TICKERS, period='5y')\n",
    "\n",
    "print(f\"✓ Data loaded: {len(prices)} trading days\")\n",
    "print(f\"  Period: {prices.index[0].date()} to {prices.index[-1].date()}\")\n",
    "print(f\"\\nPrice Data (first 5 rows):\")\n",
    "print(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "returns = calculate_returns(prices)\n",
    "\n",
    "print(f\"Daily returns shape: {returns.shape}\")\n",
    "print(f\"\\nDaily returns (first 5 rows):\")\n",
    "print(returns.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nDaily Return Statistics:\")\n",
    "print(returns.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e088880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected returns and covariance\n",
    "expected_returns = calculate_expected_returns(returns, annualize=True)\n",
    "cov_matrix = calculate_cov_matrix(returns, annualize=True)\n",
    "\n",
    "print(\"Expected Annual Returns:\")\n",
    "for ticker, ret in zip(TICKERS, expected_returns):\n",
    "    print(f\"  {ticker:6s}: {ret:7.2%}\")\n",
    "\n",
    "print(f\"\\nAnnualized Volatility (Risk):\")\n",
    "for ticker, vol in zip(TICKERS, np.sqrt(np.diag(cov_matrix))):\n",
    "    print(f\"  {ticker:6s}: {vol:7.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix\n",
    "corr_matrix = cov_matrix / np.outer(\n",
    "    np.sqrt(np.diag(cov_matrix)), \n",
    "    np.sqrt(np.diag(cov_matrix))\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            xticklabels=TICKERS, yticklabels=TICKERS, vmin=-1, vmax=1,\n",
    "            cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Asset Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(\"- Tech stocks (AAPL, MSFT, GOOGL, AMZN, NVDA) are highly correlated\")\n",
    "print(\"- Energy (XOM) and Healthcare (JNJ) provide diversification\")\n",
    "print(\"- This justifies the need for optimization rather than equal-weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b88b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Mean-Variance Optimization (Markowitz Theory)\n",
    "\n",
    "### What is Mean-Variance Optimization?\n",
    "\n",
    "Mean-Variance optimization, developed by Harry Markowitz, finds the portfolio weights that maximize risk-adjusted returns.\n",
    "\n",
    "**The Problem:**\n",
    "Maximize the Sharpe Ratio = (Portfolio Return - Risk-Free Rate) / Portfolio Volatility\n",
    "\n",
    "**Key Concept:** We want high returns with low volatility (risk).\n",
    "\n",
    "**The Efficient Frontier:** The set of optimal portfolios offering the highest expected return for a given level of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8032c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer\n",
    "mv_optimizer = MeanVarianceOptimizer(\n",
    "    expected_returns, \n",
    "    cov_matrix, \n",
    "    risk_free_rate=RISK_FREE_RATE\n",
    ")\n",
    "\n",
    "print(\"MeanVarianceOptimizer created with:\")\n",
    "print(f\"  - {len(expected_returns)} assets\")\n",
    "print(f\"  - Risk-free rate: {RISK_FREE_RATE:.2%}\")\n",
    "print(f\"  - Objective: Maximize Sharpe Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149924e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the efficient frontier (50 points)\n",
    "print(\"Calculating efficient frontier (50 points)...\")\n",
    "frontier_returns, frontier_vols, frontier_weights = mv_optimizer.efficient_frontier(n_points=50)\n",
    "\n",
    "print(f\"✓ Efficient frontier calculated\")\n",
    "print(f\"  Return range: {frontier_returns.min():.2%} to {frontier_returns.max():.2%}\")\n",
    "print(f\"  Volatility range: {frontier_vols.min():.2%} to {frontier_vols.max():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Maximum Sharpe Ratio portfolio\n",
    "max_sharpe_result = mv_optimizer.optimize_max_sharpe()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MAXIMUM SHARPE RATIO PORTFOLIO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Expected Return:  {max_sharpe_result['return']:>8.2%}\")\n",
    "print(f\"Volatility:       {max_sharpe_result['volatility']:>8.2%}\")\n",
    "print(f\"Sharpe Ratio:     {max_sharpe_result['sharpe_ratio']:>8.4f}\")\n",
    "\n",
    "print(f\"\\nPortfolio Allocation:\")\n",
    "for ticker, weight in zip(TICKERS, max_sharpe_result['weights']):\n",
    "    if weight > 0.001:\n",
    "        print(f\"  {ticker:6s}: {weight:6.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c50e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Minimum Variance portfolio\n",
    "min_var_result = mv_optimizer.optimize_min_variance()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MINIMUM VARIANCE PORTFOLIO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Expected Return:  {min_var_result['return']:>8.2%}\")\n",
    "print(f\"Volatility:       {min_var_result['volatility']:>8.2%}\")\n",
    "print(f\"Sharpe Ratio:     {min_var_result['sharpe_ratio']:>8.4f}\")\n",
    "\n",
    "print(f\"\\nPortfolio Allocation:\")\n",
    "for ticker, weight in zip(TICKERS, min_var_result['weights']):\n",
    "    if weight > 0.001:\n",
    "        print(f\"  {ticker:6s}: {weight:6.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the efficient frontier with optimal portfolios\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot frontier\n",
    "ax.plot(frontier_vols, frontier_returns, 'b-', linewidth=2.5, label='Efficient Frontier')\n",
    "\n",
    "# Plot individual assets\n",
    "asset_vols = np.sqrt(np.diag(cov_matrix))\n",
    "ax.scatter(asset_vols, expected_returns, s=100, alpha=0.6, label='Individual Assets', color='gray')\n",
    "\n",
    "# Annotate assets\n",
    "for ticker, vol, ret in zip(TICKERS, asset_vols, expected_returns):\n",
    "    ax.annotate(ticker, (vol, ret), xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "# Plot optimal portfolios\n",
    "ax.scatter(max_sharpe_result['volatility'], max_sharpe_result['return'], \n",
    "          marker='*', color='red', s=800, label='Max Sharpe Ratio', zorder=5, edgecolors='darkred', linewidth=2)\n",
    "ax.scatter(min_var_result['volatility'], min_var_result['return'], \n",
    "          marker='s', color='green', s=150, label='Min Variance', zorder=5, edgecolors='darkgreen', linewidth=2)\n",
    "\n",
    "# Equal weight portfolio\n",
    "equal_weights = np.ones(len(TICKERS)) / len(TICKERS)\n",
    "equal_ret = np.dot(equal_weights, expected_returns)\n",
    "equal_vol = np.sqrt(np.dot(equal_weights, np.dot(cov_matrix, equal_weights)))\n",
    "ax.scatter(equal_vol, equal_ret, marker='^', color='orange', s=150, label='Equal Weight', zorder=5, edgecolors='darkorange', linewidth=2)\n",
    "\n",
    "# Plot capital allocation line (CAL) from risk-free rate through max Sharpe\n",
    "cal_x = np.array([0, max_sharpe_result['volatility'] * 1.5])\n",
    "cal_y = RISK_FREE_RATE + max_sharpe_result['sharpe_ratio'] * cal_x\n",
    "ax.plot(cal_x, cal_y, 'r--', linewidth=1.5, alpha=0.7, label='Capital Allocation Line')\n",
    "\n",
    "ax.set_xlabel('Volatility (Risk)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Expected Return', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Efficient Frontier: Mean-Variance Optimization', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"• The efficient frontier shows the best risk-return tradeoff\")\n",
    "print(\"• Red star: Maximum Sharpe ratio portfolio (best risk-adjusted returns)\")\n",
    "print(\"• Green square: Minimum variance portfolio (lowest risk)\")\n",
    "print(\"• Capital Allocation Line: Shows the efficient borrowing/lending frontier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db8344",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Black-Litterman Model with Investor Views\n",
    "\n",
    "### What is the Black-Litterman Model?\n",
    "\n",
    "The Black-Litterman model combines:\n",
    "1. **Market Equilibrium** (Prior): What the market is already pricing in\n",
    "2. **Investor Views** (New Information): Your specific predictions about returns\n",
    "3. **Confidence Levels**: How much you trust your views\n",
    "\n",
    "**Why use BL?**\n",
    "- Mean-Variance optimization can produce extreme allocations\n",
    "- BL incorporates investor insights systematically\n",
    "- Produces more stable, realistic portfolios\n",
    "- Less sensitive to estimation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3241c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Black-Litterman model\n",
    "# Market weights (based on approximate market capitalization)\n",
    "market_weights = np.array([3.0, 2.8, 2.5, 2.2, 1.8, 0.8, 0.6, 0.5])\n",
    "market_weights = market_weights / market_weights.sum()\n",
    "\n",
    "print(\"Market Equilibrium Weights:\")\n",
    "for ticker, weight in zip(TICKERS, market_weights):\n",
    "    print(f\"  {ticker:6s}: {weight:6.2%}\")\n",
    "\n",
    "# Create Black-Litterman model\n",
    "bl_model = BlackLittermanModel(\n",
    "    cov_matrix, \n",
    "    risk_aversion=2.5, \n",
    "    risk_free_rate=RISK_FREE_RATE\n",
    ")\n",
    "bl_model.set_market_weights(market_weights)\n",
    "\n",
    "# Calculate implied equilibrium returns\n",
    "eq_returns = bl_model.calculate_equilibrium_returns()\n",
    "\n",
    "print(f\"\\nImplied Equilibrium Returns:\")\n",
    "for ticker, ret in zip(TICKERS, eq_returns):\n",
    "    print(f\"  {ticker:6s}: {ret:7.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43932592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add investor views\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADDING INVESTOR VIEWS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# View 1: NVDA will outperform AAPL by 3%\n",
    "view_P_1 = np.zeros(len(TICKERS))\n",
    "view_P_1[TICKERS.index('NVDA')] = 1\n",
    "view_P_1[TICKERS.index('AAPL')] = -1\n",
    "bl_model.add_view(view_P_1, 0.03, confidence=0.7)\n",
    "print(\"\\nView 1: NVDA will outperform AAPL by 3%\")\n",
    "print(\"  Confidence: 70%\")\n",
    "print(\"  Interpretation: We believe NVDA's returns exceed AAPL's by 3%\")\n",
    "\n",
    "# View 2: Tech sector average will return 12%\n",
    "view_P_2 = np.zeros(len(TICKERS))\n",
    "tech_indices = [TICKERS.index(t) for t in ['AAPL', 'MSFT', 'GOOGL', 'NVDA']]\n",
    "for idx in tech_indices:\n",
    "    view_P_2[idx] = 0.25  # Equal weight within tech\n",
    "bl_model.add_view(view_P_2, 0.12, confidence=0.6)\n",
    "print(\"\\nView 2: Tech sector average return will be 12%\")\n",
    "print(\"  Confidence: 60%\")\n",
    "print(\"  Assets: AAPL, MSFT, GOOGL, NVDA\")\n",
    "\n",
    "# View 3: Energy will outperform Financials by 2%\n",
    "view_P_3 = np.zeros(len(TICKERS))\n",
    "view_P_3[TICKERS.index('XOM')] = 1\n",
    "view_P_3[TICKERS.index('JPM')] = -1\n",
    "bl_model.add_view(view_P_3, 0.02, confidence=0.5)\n",
    "print(\"\\nView 3: XOM will outperform JPM by 2%\")\n",
    "print(\"  Confidence: 50%\")\n",
    "print(\"  Interpretation: Slight bullish tilt toward energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30019f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Black-Litterman model\n",
    "posterior_returns = bl_model.fit(use_equilibrium=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POSTERIOR EXPECTED RETURNS (with Views)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Historical': expected_returns,\n",
    "    'Equilibrium': eq_returns,\n",
    "    'BL Posterior': posterior_returns,\n",
    "    'Change': posterior_returns - eq_returns\n",
    "}, index=TICKERS)\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string())\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"• Equilibrium: What the market implies about returns\")\n",
    "print(\"• BL Posterior: After incorporating our views\")\n",
    "print(\"• Change: How much our views adjusted the returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize with Black-Litterman returns\n",
    "bl_optimizer = MeanVarianceOptimizer(posterior_returns, cov_matrix, RISK_FREE_RATE)\n",
    "bl_result = bl_optimizer.optimize_max_sharpe()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BLACK-LITTERMAN OPTIMIZED PORTFOLIO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Expected Return:  {bl_result['return']:>8.2%}\")\n",
    "print(f\"Volatility:       {bl_result['volatility']:>8.2%}\")\n",
    "print(f\"Sharpe Ratio:     {bl_result['sharpe_ratio']:>8.4f}\")\n",
    "\n",
    "print(f\"\\nPortfolio Allocation:\")\n",
    "for ticker, weight in zip(TICKERS, bl_result['weights']):\n",
    "    if weight > 0.001:\n",
    "        print(f\"  {ticker:6s}: {weight:6.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare allocations: MV vs BL\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# MV allocation\n",
    "ax = axes[0]\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(TICKERS)))\n",
    "ax.barh(TICKERS, max_sharpe_result['weights'] * 100, color=colors)\n",
    "ax.set_xlabel('Weight (%)', fontsize=11)\n",
    "ax.set_title('Mean-Variance Max Sharpe\\nAllocation', fontsize=12, fontweight='bold')\n",
    "ax.set_xlim(0, max(max_sharpe_result['weights']) * 100 * 1.1)\n",
    "for i, w in enumerate(max_sharpe_result['weights']):\n",
    "    if w > 0.01:\n",
    "        ax.text(w * 100 + 1, i, f'{w:.1%}', va='center')\n",
    "\n",
    "# BL allocation\n",
    "ax = axes[1]\n",
    "ax.barh(TICKERS, bl_result['weights'] * 100, color=colors)\n",
    "ax.set_xlabel('Weight (%)', fontsize=11)\n",
    "ax.set_title('Black-Litterman\\nAllocation', fontsize=12, fontweight='bold')\n",
    "ax.set_xlim(0, max(bl_result['weights']) * 100 * 1.1)\n",
    "for i, w in enumerate(bl_result['weights']):\n",
    "    if w > 0.01:\n",
    "        ax.text(w * 100 + 1, i, f'{w:.1%}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"MV Sharpe Ratio:    {max_sharpe_result['sharpe_ratio']:.4f}\")\n",
    "print(f\"BL Sharpe Ratio:    {bl_result['sharpe_ratio']:.4f}\")\n",
    "print(f\"Improvement:        {(bl_result['sharpe_ratio'] / max_sharpe_result['sharpe_ratio'] - 1) * 100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee412cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Portfolio Backtesting with Transaction Costs\n",
    "\n",
    "### Backtesting: The Reality Check\n",
    "\n",
    "Theory is great, but how do strategies perform in practice with realistic costs?\n",
    "\n",
    "**What we simulate:**\n",
    "- Transaction costs (broker commissions)\n",
    "- Slippage (impact of execution)\n",
    "- Rebalancing frequency\n",
    "- Portfolio performance over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get monthly rebalancing dates\n",
    "monthly_dates = prices.index[prices.index.is_month_end]\n",
    "\n",
    "print(f\"Rebalancing frequency: Monthly\")\n",
    "print(f\"Total rebalance dates: {len(monthly_dates)}\")\n",
    "print(f\"Time period: {monthly_dates[0].date()} to {monthly_dates[-1].date()}\")\n",
    "print(f\"Transaction cost: 0.1% (spread + commission)\")\n",
    "print(f\"Slippage: 0.05% (execution impact)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e958ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Mean-Variance Max Sharpe (Monthly Rebalancing)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY 1: Mean-Variance Max Sharpe (Monthly Rebalancing)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "weights_mv = {date: max_sharpe_result['weights'] for date in monthly_dates}\n",
    "\n",
    "backtest_mv = PortfolioBacktester(prices, INITIAL_CAPITAL)\n",
    "results_mv = backtest_mv.run_backtest(\n",
    "    weights_mv,\n",
    "    rebalance_frequency='monthly',\n",
    "    transaction_cost=0.001,  # 0.1%\n",
    "    slippage=0.0005  # 0.05%\n",
    ")\n",
    "\n",
    "metrics_mv = backtest_mv.calculate_metrics(results_mv)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Initial Capital:      ${INITIAL_CAPITAL:>12,.0f}\")\n",
    "print(f\"  Final Value:          ${metrics_mv['final_value']:>12,.0f}\")\n",
    "print(f\"  Total Return:         {metrics_mv['total_return']:>12.2%}\")\n",
    "print(f\"  Annual Return:        {metrics_mv['annual_return']:>12.2%}\")\n",
    "print(f\"  Annual Volatility:    {metrics_mv['annual_volatility']:>12.2%}\")\n",
    "print(f\"  Sharpe Ratio:         {metrics_mv['sharpe_ratio']:>12.4f}\")\n",
    "print(f\"  Maximum Drawdown:     {metrics_mv['max_drawdown']:>12.2%}\")\n",
    "print(f\"  Rebalances:           {metrics_mv['transactions']:>12d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2: Black-Litterman (Monthly Rebalancing)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY 2: Black-Litterman (Monthly Rebalancing)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "weights_bl = {date: bl_result['weights'] for date in monthly_dates}\n",
    "\n",
    "backtest_bl = PortfolioBacktester(prices, INITIAL_CAPITAL)\n",
    "results_bl = backtest_bl.run_backtest(\n",
    "    weights_bl,\n",
    "    rebalance_frequency='monthly',\n",
    "    transaction_cost=0.001,\n",
    "    slippage=0.0005\n",
    ")\n",
    "\n",
    "metrics_bl = backtest_bl.calculate_metrics(results_bl)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Initial Capital:      ${INITIAL_CAPITAL:>12,.0f}\")\n",
    "print(f\"  Final Value:          ${metrics_bl['final_value']:>12,.0f}\")\n",
    "print(f\"  Total Return:         {metrics_bl['total_return']:>12.2%}\")\n",
    "print(f\"  Annual Return:        {metrics_bl['annual_return']:>12.2%}\")\n",
    "print(f\"  Annual Volatility:    {metrics_bl['annual_volatility']:>12.2%}\")\n",
    "print(f\"  Sharpe Ratio:         {metrics_bl['sharpe_ratio']:>12.4f}\")\n",
    "print(f\"  Maximum Drawdown:     {metrics_bl['max_drawdown']:>12.2%}\")\n",
    "print(f\"  Rebalances:           {metrics_bl['transactions']:>12d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 3: Buy and Hold (Equal Weight)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY 3: Buy and Hold (Equal Weight - No Rebalancing)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "equal_weights = np.ones(len(TICKERS)) / len(TICKERS)\n",
    "\n",
    "backtest_bh = PortfolioBacktester(prices, INITIAL_CAPITAL)\n",
    "results_bh = backtest_bh.run_buy_and_hold(equal_weights, transaction_cost=0.001)\n",
    "\n",
    "metrics_bh = backtest_bh.calculate_metrics(results_bh)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Initial Capital:      ${INITIAL_CAPITAL:>12,.0f}\")\n",
    "print(f\"  Final Value:          ${metrics_bh['final_value']:>12,.0f}\")\n",
    "print(f\"  Total Return:         {metrics_bh['total_return']:>12.2%}\")\n",
    "print(f\"  Annual Return:        {metrics_bh['annual_return']:>12.2%}\")\n",
    "print(f\"  Annual Volatility:    {metrics_bh['annual_volatility']:>12.2%}\")\n",
    "print(f\"  Sharpe Ratio:         {metrics_bh['sharpe_ratio']:>12.4f}\")\n",
    "print(f\"  Maximum Drawdown:     {metrics_bh['max_drawdown']:>12.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00149cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative performance\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Cumulative value\n",
    "ax = axes[0]\n",
    "ax.plot(results_mv['date'], results_mv['portfolio_value'], linewidth=2.5, label='Mean-Variance')\n",
    "ax.plot(results_bl['date'], results_bl['portfolio_value'], linewidth=2.5, label='Black-Litterman')\n",
    "ax.plot(results_bh['date'], results_bh['portfolio_value'], linewidth=2.5, label='Buy & Hold (Equal Weight)')\n",
    "ax.axhline(y=INITIAL_CAPITAL, color='black', linestyle='--', alpha=0.5, label='Initial Capital')\n",
    "ax.set_ylabel('Portfolio Value ($)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Backtest: Cumulative Portfolio Performance (5 Years)', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))\n",
    "\n",
    "# Drawdown\n",
    "ax = axes[1]\n",
    "def calculate_drawdown(values):\n",
    "    cum_returns = (1 + values).cumprod()\n",
    "    running_max = np.maximum.accumulate(cum_returns)\n",
    "    return (cum_returns - running_max) / running_max\n",
    "\n",
    "returns_mv = results_mv['daily_return'].dropna().values\n",
    "returns_bl = results_bl['daily_return'].dropna().values\n",
    "returns_bh = results_bh['daily_return'].dropna().values\n",
    "\n",
    "drawdown_mv = calculate_drawdown(returns_mv)\n",
    "drawdown_bl = calculate_drawdown(returns_bl)\n",
    "drawdown_bh = calculate_drawdown(returns_bh)\n",
    "\n",
    "ax.fill_between(range(len(drawdown_mv)), drawdown_mv * 100, alpha=0.5, label='Mean-Variance')\n",
    "ax.fill_between(range(len(drawdown_bl)), drawdown_bl * 100, alpha=0.5, label='Black-Litterman')\n",
    "ax.fill_between(range(len(drawdown_bh)), drawdown_bh * 100, alpha=0.5, label='Buy & Hold')\n",
    "ax.set_ylabel('Drawdown (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_xlabel('Days', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Drawdown Over Time', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='lower left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "comparison = pd.DataFrame({\n",
    "    'Mean-Variance': [\n",
    "        metrics_mv['final_value'],\n",
    "        metrics_mv['total_return'],\n",
    "        metrics_mv['annual_return'],\n",
    "        metrics_mv['annual_volatility'],\n",
    "        metrics_mv['sharpe_ratio'],\n",
    "        metrics_mv['max_drawdown']\n",
    "    ],\n",
    "    'Black-Litterman': [\n",
    "        metrics_bl['final_value'],\n",
    "        metrics_bl['total_return'],\n",
    "        metrics_bl['annual_return'],\n",
    "        metrics_bl['annual_volatility'],\n",
    "        metrics_bl['sharpe_ratio'],\n",
    "        metrics_bl['max_drawdown']\n",
    "    ],\n",
    "    'Buy & Hold': [\n",
    "        metrics_bh['final_value'],\n",
    "        metrics_bh['total_return'],\n",
    "        metrics_bh['annual_return'],\n",
    "        metrics_bh['annual_volatility'],\n",
    "        metrics_bh['sharpe_ratio'],\n",
    "        metrics_bh['max_drawdown']\n",
    "    ]\n",
    "}, index=['Final Value', 'Total Return', 'Annual Return', 'Annual Volatility', 'Sharpe Ratio', 'Max Drawdown'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(comparison.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86574a2a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Impact of Transaction Costs\n",
    "\n",
    "Transaction costs (fees, spreads, slippage) significantly impact real-world performance.\n",
    "\n",
    "Let's analyze how sensitive our strategies are to different cost levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cost sensitivity\n",
    "cost_levels = [0.0001, 0.0005, 0.001, 0.002, 0.005]\n",
    "\n",
    "results_by_cost = {'Mean-Variance': [], 'Black-Litterman': []}\n",
    "\n",
    "for cost in cost_levels:\n",
    "    # Mean-Variance\n",
    "    backtest = PortfolioBacktester(prices, INITIAL_CAPITAL)\n",
    "    results = backtest.run_backtest(weights_mv, transaction_cost=cost)\n",
    "    metrics = backtest.calculate_metrics(results)\n",
    "    results_by_cost['Mean-Variance'].append({\n",
    "        'cost': cost,\n",
    "        'annual_return': metrics['annual_return'],\n",
    "        'sharpe': metrics['sharpe_ratio']\n",
    "    })\n",
    "    \n",
    "    # Black-Litterman\n",
    "    backtest = PortfolioBacktester(prices, INITIAL_CAPITAL)\n",
    "    results = backtest.run_backtest(weights_bl, transaction_cost=cost)\n",
    "    metrics = backtest.calculate_metrics(results)\n",
    "    results_by_cost['Black-Litterman'].append({\n",
    "        'cost': cost,\n",
    "        'annual_return': metrics['annual_return'],\n",
    "        'sharpe': metrics['sharpe_ratio']\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSACTION COST SENSITIVITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Cost':<10} {'MV Return':<15} {'MV Sharpe':<15} {'BL Return':<15} {'BL Sharpe':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, cost in enumerate(cost_levels):\n",
    "    mv_data = results_by_cost['Mean-Variance'][i]\n",
    "    bl_data = results_by_cost['Black-Litterman'][i]\n",
    "    print(f\"{cost:<10.4%} {mv_data['annual_return']:<14.2%} {mv_data['sharpe']:<14.4f} \"\n",
    "          f\"{bl_data['annual_return']:<14.2%} {bl_data['sharpe']:<14.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88209ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cost sensitivity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Returns vs costs\n",
    "ax = axes[0]\n",
    "costs_pct = [c * 100 for c in cost_levels]\n",
    "mv_returns = [r['annual_return'] * 100 for r in results_by_cost['Mean-Variance']]\n",
    "bl_returns = [r['annual_return'] * 100 for r in results_by_cost['Black-Litterman']]\n",
    "\n",
    "ax.plot(costs_pct, mv_returns, marker='o', linewidth=2, markersize=8, label='Mean-Variance')\n",
    "ax.plot(costs_pct, bl_returns, marker='s', linewidth=2, markersize=8, label='Black-Litterman')\n",
    "ax.set_xlabel('Transaction Cost (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Annual Return (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Annual Return vs Transaction Cost', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Sharpe ratio vs costs\n",
    "ax = axes[1]\n",
    "mv_sharpes = [r['sharpe'] for r in results_by_cost['Mean-Variance']]\n",
    "bl_sharpes = [r['sharpe'] for r in results_by_cost['Black-Litterman']]\n",
    "\n",
    "ax.plot(costs_pct, mv_sharpes, marker='o', linewidth=2, markersize=8, label='Mean-Variance')\n",
    "ax.plot(costs_pct, bl_sharpes, marker='s', linewidth=2, markersize=8, label='Black-Litterman')\n",
    "ax.set_xlabel('Transaction Cost (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Sharpe Ratio', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Risk-Adjusted Return vs Transaction Cost', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"• Even 0.1% transaction cost reduces annual returns by ~0.3%\")\n",
    "print(\"• Higher costs favor less frequent rebalancing\")\n",
    "print(\"• Black-Litterman remains superior across all cost levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad275a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Stress Testing and Scenario Analysis\n",
    "\n",
    "### What Happens When Markets Crash?\n",
    "\n",
    "We simulate 7 different market scenarios to stress-test our portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scenario analyzer\n",
    "scenario_analyzer = ScenarioAnalyzer(TICKERS, expected_returns, cov_matrix)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCENARIO STRESS TESTING (100 simulations per scenario)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run scenarios for both portfolios\n",
    "mv_scenarios = scenario_analyzer.run_all_scenarios(\n",
    "    max_sharpe_result['weights'], \n",
    "    periods=252, \n",
    "    n_simulations=100\n",
    ")\n",
    "\n",
    "bl_scenarios = scenario_analyzer.run_all_scenarios(\n",
    "    bl_result['weights'], \n",
    "    periods=252, \n",
    "    n_simulations=100\n",
    ")\n",
    "\n",
    "print(\"\\nScenario Results for Mean-Variance Portfolio:\")\n",
    "print(f\"{'Scenario':<20} {'Avg Value':<12} {'Worst Case':<12} {'Loss Prob':<12}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "for scenario_name, metrics in mv_scenarios.items():\n",
    "    print(f\"{scenario_name:<20} {metrics['avg_final_value']:<11.3f} \"\n",
    "          f\"{metrics['worst_case_loss']:<11.2%} {metrics['prob_loss']:<11.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef314906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nScenario Results for Black-Litterman Portfolio:\")\n",
    "print(f\"{'Scenario':<20} {'Avg Value':<12} {'Worst Case':<12} {'Loss Prob':<12}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "for scenario_name, metrics in bl_scenarios.items():\n",
    "    print(f\"{scenario_name:<20} {metrics['avg_final_value']:<11.3f} \"\n",
    "          f\"{metrics['worst_case_loss']:<11.2%} {metrics['prob_loss']:<11.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scenario comparison\n",
    "scenarios = list(mv_scenarios.keys())\n",
    "mv_probs = [mv_scenarios[s]['prob_loss'] for s in scenarios]\n",
    "bl_probs = [bl_scenarios[s]['prob_loss'] for s in scenarios]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Probability of loss\n",
    "ax = axes[0]\n",
    "x = np.arange(len(scenarios))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, np.array(mv_probs) * 100, width, label='Mean-Variance', alpha=0.8)\n",
    "ax.bar(x + width/2, np.array(bl_probs) * 100, width, label='Black-Litterman', alpha=0.8)\n",
    "ax.set_ylabel('Probability of Loss (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Probability of Portfolio Loss by Scenario', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([s.replace(' ', '\\n') for s in scenarios], fontsize=9)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Worst case loss\n",
    "ax = axes[1]\n",
    "mv_worst = [mv_scenarios[s]['worst_case_loss'] for s in scenarios]\n",
    "bl_worst = [bl_scenarios[s]['worst_case_loss'] for s in scenarios]\n",
    "ax.bar(x - width/2, np.array(mv_worst) * 100, width, label='Mean-Variance', alpha=0.8)\n",
    "ax.bar(x + width/2, np.array(bl_worst) * 100, width, label='Black-Litterman', alpha=0.8)\n",
    "ax.set_ylabel('Worst Case Loss (%)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Worst Case Scenario Loss', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([s.replace(' ', '\\n') for s in scenarios], fontsize=9)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"• Crisis scenario: Both portfolios face significant loss risk\")\n",
    "print(\"• Bull market: Clearly the best outcome for growth\")\n",
    "print(\"• Volatility spike: High risk despite normal returns\")\n",
    "print(\"• BL portfolio slightly more resilient in downturns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1eb56",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Rebalancing Strategies Comparison\n",
    "\n",
    "### How often should we rebalance?\n",
    "\n",
    "More frequent rebalancing:\n",
    "- ✓ Keeps portfolio closer to target\n",
    "- ✗ Increases transaction costs\n",
    "- ✗ More time-intensive\n",
    "\n",
    "Less frequent rebalancing:\n",
    "- ✓ Lower costs\n",
    "- ✓ Easier to manage\n",
    "- ✗ Portfolio drifts from targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f364a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different rebalancing frequencies\n",
    "rebalance_frequencies = [\n",
    "    ('No Rebalance', [prices.index[0]]),\n",
    "    ('Quarterly', prices.index[prices.index.is_month_end][::3]),\n",
    "    ('Monthly', prices.index[prices.index.is_month_end]),\n",
    "    ('Weekly', prices.index[prices.index.dayofweek == 4]),  # Fridays\n",
    "]\n",
    "\n",
    "freq_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REBALANCING FREQUENCY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for freq_name, freq_dates in rebalance_frequencies:\n",
    "    # Mean-Variance\n",
    "    weights_dict = {date: max_sharpe_result['weights'] for date in freq_dates}\n",
    "    backtest = PortfolioBacktester(prices, INITIAL_CAPITAL)\n",
    "    results = backtest.run_backtest(weights_dict, transaction_cost=0.001)\n",
    "    metrics = backtest.calculate_metrics(results)\n",
    "    \n",
    "    freq_results.append({\n",
    "        'frequency': freq_name,\n",
    "        'annual_return': metrics['annual_return'],\n",
    "        'annual_vol': metrics['annual_volatility'],\n",
    "        'sharpe': metrics['sharpe_ratio'],\n",
    "        'max_dd': metrics['max_drawdown'],\n",
    "        'rebalances': metrics['transactions']\n",
    "    })\n",
    "\n",
    "freq_df = pd.DataFrame(freq_results)\n",
    "print(\"\\nMean-Variance Portfolio - Transaction Cost: 0.1%\\n\")\n",
    "print(freq_df[['frequency', 'annual_return', 'annual_vol', 'sharpe', 'rebalances']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rebalancing frequency impact\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Return vs frequency\n",
    "ax = axes[0, 0]\n",
    "ax.bar(freq_df['frequency'], freq_df['annual_return'] * 100, color='steelblue', alpha=0.8)\n",
    "ax.set_ylabel('Annual Return (%)', fontsize=10, fontweight='bold')\n",
    "ax.set_title('Annual Return by Rebalancing Frequency', fontsize=11, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Sharpe ratio vs frequency\n",
    "ax = axes[0, 1]\n",
    "ax.bar(freq_df['frequency'], freq_df['sharpe'], color='seagreen', alpha=0.8)\n",
    "ax.set_ylabel('Sharpe Ratio', fontsize=10, fontweight='bold')\n",
    "ax.set_title('Risk-Adjusted Return by Frequency', fontsize=11, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Volatility vs frequency\n",
    "ax = axes[1, 0]\n",
    "ax.bar(freq_df['frequency'], freq_df['annual_vol'] * 100, color='coral', alpha=0.8)\n",
    "ax.set_ylabel('Annual Volatility (%)', fontsize=10, fontweight='bold')\n",
    "ax.set_title('Risk by Rebalancing Frequency', fontsize=11, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Rebalance count vs frequency\n",
    "ax = axes[1, 1]\n",
    "ax.bar(freq_df['frequency'], freq_df['rebalances'], color='mediumpurple', alpha=0.8)\n",
    "ax.set_ylabel('Number of Rebalances', fontsize=10, fontweight='bold')\n",
    "ax.set_title('Transaction Count by Frequency', fontsize=11, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"• Monthly rebalancing offers best balance of performance and costs\")\n",
    "print(\"• Weekly rebalancing: Minimal improvement, higher costs\")\n",
    "print(\"• No rebalancing: Significant drift from optimal allocation over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e384998",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Takeaways\n",
    "\n",
    "### 1. **Mean-Variance Optimization**\n",
    "- Solves for maximum Sharpe ratio\n",
    "- Produces efficient frontier\n",
    "- Simple but can result in extreme allocations\n",
    "- Sensitive to estimation errors in expected returns\n",
    "\n",
    "### 2. **Black-Litterman Model**\n",
    "- Incorporates investor views systematically\n",
    "- Uses market equilibrium as baseline\n",
    "- Confidence weighting for views\n",
    "- Produces more stable allocations\n",
    "- **Generally superior to pure MV optimization**\n",
    "\n",
    "### 3. **Transaction Costs Matter**\n",
    "- Even 0.1% costs reduce returns by ~0.3% annually\n",
    "- Monthly rebalancing is optimal for most strategies\n",
    "- More frequent rebalancing rarely justified by performance gains\n",
    "\n",
    "### 4. **Stress Testing**\n",
    "- Critical for understanding tail risks\n",
    "- Portfolio diversification reduces crisis losses\n",
    "- No portfolio is immune to severe downturns\n",
    "- BL portfolios slightly more resilient\n",
    "\n",
    "### 5. **Risk-Return Tradeoff**\n",
    "- Higher returns come with higher risk\n",
    "- Sharpe ratio balances both\n",
    "- Maximum drawdown important for investor psychology\n",
    "- Diversification is crucial\n",
    "\n",
    "### 6. **Practical Considerations**\n",
    "- Implement in stages (don't go all-in at once)\n",
    "- Monitor allocations regularly\n",
    "- Adjust views as new information emerges\n",
    "- Consider investor constraints (taxes, liquidity, etc.)\n",
    "- Rebalance when allocations drift >5-10% from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY: OPTIMAL PORTFOLIO SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_final = pd.DataFrame({\n",
    "    'Mean-Variance': [\n",
    "        f\"{max_sharpe_result['sharpe_ratio']:.4f}\",\n",
    "        f\"{metrics_mv['annual_return']:.2%}\",\n",
    "        f\"{metrics_mv['annual_volatility']:.2%}\",\n",
    "        f\"{metrics_mv['max_drawdown']:.2%}\",\n",
    "        f\"${metrics_mv['final_value']:,.0f}\"\n",
    "    ],\n",
    "    'Black-Litterman': [\n",
    "        f\"{bl_result['sharpe_ratio']:.4f}\",\n",
    "        f\"{metrics_bl['annual_return']:.2%}\",\n",
    "        f\"{metrics_bl['annual_volatility']:.2%}\",\n",
    "        f\"{metrics_bl['max_drawdown']:.2%}\",\n",
    "        f\"${metrics_bl['final_value']:,.0f}\"\n",
    "    ],\n",
    "    'Buy & Hold': [\n",
    "        f\"{metrics_bh['sharpe_ratio']:.4f}\",\n",
    "        f\"{metrics_bh['annual_return']:.2%}\",\n",
    "        f\"{metrics_bh['annual_volatility']:.2%}\",\n",
    "        f\"{metrics_bh['max_drawdown']:.2%}\",\n",
    "        f\"${metrics_bh['final_value']:,.0f}\"\n",
    "    ]\n",
    "}, index=['Sharpe Ratio', 'Annual Return', 'Annual Volatility', 'Max Drawdown', 'Final Value'])\n",
    "\n",
    "print(\"\\n\" + comparison_final.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✓ Use Black-Litterman model for most investors:\")\n",
    "print(\"  - Better risk-adjusted returns\")\n",
    "print(\"  - More intuitive (incorporate your own views)\")\n",
    "print(\"  - More stable allocations\")\n",
    "print(\"  - Less sensitive to estimation errors\")\n",
    "print(\"\\n✓ Implement with:\")\n",
    "print(\"  - Monthly rebalancing\")\n",
    "print(\"  - 0.1% transaction cost assumption\")\n",
    "print(\"  - Clear, confident investor views\")\n",
    "print(\"  - Regular monitoring and updates\")\n",
    "print(\"\\n✓ Monitor:\")\n",
    "print(\"  - Portfolio drift from targets\")\n",
    "print(\"  - Changes in market conditions\")\n",
    "print(\"  - Updated expected returns\")\n",
    "print(\"  - Risk tolerance changes\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
